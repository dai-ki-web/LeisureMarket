{"version":3,"sources":["index.js","options.js","fetch.js","cache/policy.js","cache/index.js","cache/errors.js","cache/entry.js","cache/key.js","remote.js","agent.js","../package.json"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AGRA,ADGA,ADGA,AFMA,ACHA;AGRA,ADGA,ADGA,AFMA,ACHA;AGRA,ADGA,ADGA,AFMA,ACHA;AIXA,ADGA,ADGA,ADGA,AFMA,ACHA;AIXA,ADGA,ADGA,ADGA,AFMA,ACHA;AIXA,ADGA,ADGA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,ADGA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,ADGA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,ADGA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,AGTA,AJYA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,AGTA,AJYA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,AGTA,AJYA,ADGA,AFMA,ACHA;AKdA,ADGA,ADGA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AFOA,ADGA,ADGA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AFOA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;ACFA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;ACFA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;ACFA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,AGTA,AJYA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AFMA,ACHA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,ADGA,AOrBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AFMA,ADGA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,ADGA,AMlBA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA,AKfA;AELA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AOpBA,ADGA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA,AHSA;AMjBA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AGRA,AHSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["const { FetchError, Headers, Request, Response } = require('minipass-fetch')\n\nconst configureOptions = require('./options.js')\nconst fetch = require('./fetch.js')\n\nconst makeFetchHappen = (url, opts) => {\n  const options = configureOptions(opts)\n\n  const request = new Request(url, options)\n  return fetch(request, options)\n}\n\nmakeFetchHappen.defaults = (defaultUrl, defaultOptions = {}) => {\n  if (typeof defaultUrl === 'object') {\n    defaultOptions = defaultUrl\n    defaultUrl = null\n  }\n\n  const defaultedFetch = (url, options = {}) => {\n    const finalUrl = url || defaultUrl\n    const finalOptions = {\n      ...defaultOptions,\n      ...options,\n      headers: {\n        ...defaultOptions.headers,\n        ...options.headers,\n      },\n    }\n    return makeFetchHappen(finalUrl, finalOptions)\n  }\n\n  defaultedFetch.defaults = makeFetchHappen.defaults\n  return defaultedFetch\n}\n\nmodule.exports = makeFetchHappen\nmodule.exports.FetchError = FetchError\nmodule.exports.Headers = Headers\nmodule.exports.Request = Request\nmodule.exports.Response = Response\n","const conditionalHeaders = [\n  'if-modified-since',\n  'if-none-match',\n  'if-unmodified-since',\n  'if-match',\n  'if-range',\n]\n\nconst configureOptions = (opts) => {\n  const {strictSSL, ...options} = { ...opts }\n  options.method = options.method ? options.method.toUpperCase() : 'GET'\n  options.rejectUnauthorized = strictSSL !== false\n\n  if (!options.retry)\n    options.retry = { retries: 0 }\n  else if (typeof options.retry === 'string') {\n    const retries = parseInt(options.retry, 10)\n    if (isFinite(retries))\n      options.retry = { retries }\n    else\n      options.retry = { retries: 0 }\n  } else if (typeof options.retry === 'number')\n    options.retry = { retries: options.retry }\n  else\n    options.retry = { retries: 0, ...options.retry }\n\n  options.cache = options.cache || 'default'\n  if (options.cache === 'default') {\n    const hasConditionalHeader = Object.keys(options.headers || {}).some((name) => {\n      return conditionalHeaders.includes(name.toLowerCase())\n    })\n    if (hasConditionalHeader)\n      options.cache = 'no-store'\n  }\n\n  // cacheManager is deprecated, but if it's set and\n  // cachePath is not we should copy it to the new field\n  if (options.cacheManager && !options.cachePath)\n    options.cachePath = options.cacheManager\n\n  return options\n}\n\nmodule.exports = configureOptions\n","\n\nconst { FetchError, Request, isRedirect } = require('minipass-fetch')\nconst url = require('url')\n\nconst CachePolicy = require('./cache/policy.js')\nconst cache = require('./cache/index.js')\nconst remote = require('./remote.js')\n\n// given a Request, a Response and user options\n// return true if the response is a redirect that\n// can be followed. we throw errors that will result\n// in the fetch being rejected if the redirect is\n// possible but invalid for some reason\nconst canFollowRedirect = (request, response, options) => {\n  if (!isRedirect(response.status))\n    return false\n\n  if (options.redirect === 'manual')\n    return false\n\n  if (options.redirect === 'error')\n    throw new FetchError(`redirect mode is set to error: ${request.url}`, 'no-redirect', { code: 'ENOREDIRECT' })\n\n  if (!response.headers.has('location'))\n    throw new FetchError(`redirect location header missing for: ${request.url}`, 'no-location', { code: 'EINVALIDREDIRECT' })\n\n  if (request.counter >= request.follow)\n    throw new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect', { code: 'EMAXREDIRECT' })\n\n  return true\n}\n\n// given a Request, a Response, and the user's options return an object\n// with a new Request and a new options object that will be used for\n// following the redirect\nconst getRedirect = (request, response, options) => {\n  const _opts = { ...options }\n  const location = response.headers.get('location')\n  const redirectUrl = new url.URL(location, /^https?:/.test(location) ? undefined : request.url)\n  // Comment below is used under the following license:\n  // Copyright (c) 2010-2012 Mikeal Rogers\n  // Licensed under the Apache License, Version 2.0 (the \"License\");\n  // you may not use this file except in compliance with the License.\n  // You may obtain a copy of the License at\n  // http://www.apache.org/licenses/LICENSE-2.0\n  // Unless required by applicable law or agreed to in writing,\n  // software distributed under the License is distributed on an \"AS\n  // IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n  // express or implied. See the License for the specific language\n  // governing permissions and limitations under the License.\n\n  // Remove authorization if changing hostnames (but not if just\n  // changing ports or protocols).  This matches the behavior of request:\n  // https://github.com/request/request/blob/b12a6245/lib/redirect.js#L134-L138\n  if (new url.URL(request.url).hostname !== redirectUrl.hostname)\n    request.headers.delete('authorization')\n\n  // for POST request with 301/302 response, or any request with 303 response,\n  // use GET when following redirect\n  if (response.status === 303 || (request.method === 'POST' && [301, 302].includes(response.status))) {\n    _opts.method = 'GET'\n    _opts.body = null\n    request.headers.delete('content-length')\n  }\n\n  _opts.headers = {}\n  request.headers.forEach((value, key) => {\n    _opts.headers[key] = value\n  })\n\n  _opts.counter = ++request.counter\n  const redirectReq = new Request(url.format(redirectUrl), _opts)\n  return {\n    request: redirectReq,\n    options: _opts,\n  }\n}\n\nconst fetch = async (request, options) => {\n  const response = CachePolicy.storable(request, options)\n    ? await cache(request, options)\n    : await remote(request, options)\n\n  // if the request wasn't a GET or HEAD, and the response\n  // status is between 200 and 399 inclusive, invalidate the\n  // request url\n  if (!['GET', 'HEAD'].includes(request.method) &&\n      response.status >= 200 &&\n      response.status <= 399)\n    await cache.invalidate(request, options)\n\n  if (!canFollowRedirect(request, response, options))\n    return response\n\n  const redirect = getRedirect(request, response, options)\n  return fetch(redirect.request, redirect.options)\n}\n\nmodule.exports = fetch\n","const CacheSemantics = require('http-cache-semantics')\nconst Negotiator = require('negotiator')\nconst ssri = require('ssri')\n\n// HACK: negotiator lazy loads several of its own modules\n// as a micro optimization. we need to be sure that they're\n// in memory as soon as possible at startup so that we do\n// not try to lazy load them after the directory has been\n// retired during a self update of the npm CLI, we do this\n// by calling all of the methods that trigger a lazy load\n// on a fake instance.\nconst preloadNegotiator = new Negotiator({ headers: {} })\npreloadNegotiator.charsets()\npreloadNegotiator.encodings()\npreloadNegotiator.languages()\npreloadNegotiator.mediaTypes()\n\n// options passed to http-cache-semantics constructor\nconst policyOptions = {\n  shared: false,\n  ignoreCargoCult: true,\n}\n\n// a fake empty response, used when only testing the\n// request for storability\nconst emptyResponse = { status: 200, headers: {} }\n\n// returns a plain object representation of the Request\nconst requestObject = (request) => {\n  const _obj = {\n    method: request.method,\n    url: request.url,\n    headers: {},\n  }\n\n  request.headers.forEach((value, key) => {\n    _obj.headers[key] = value\n  })\n\n  return _obj\n}\n\n// returns a plain object representation of the Response\nconst responseObject = (response) => {\n  const _obj = {\n    status: response.status,\n    headers: {},\n  }\n\n  response.headers.forEach((value, key) => {\n    _obj.headers[key] = value\n  })\n\n  return _obj\n}\n\nclass CachePolicy {\n  constructor ({ entry, request, response, options }) {\n    this.entry = entry\n    this.request = requestObject(request)\n    this.response = responseObject(response)\n    this.options = options\n    this.policy = new CacheSemantics(this.request, this.response, policyOptions)\n\n    if (this.entry) {\n      // if we have an entry, copy the timestamp to the _responseTime\n      // this is necessary because the CacheSemantics constructor forces\n      // the value to Date.now() which means a policy created from a\n      // cache entry is likely to always identify itself as stale\n      this.policy._responseTime = this.entry.metadata.time\n    }\n  }\n\n  // static method to quickly determine if a request alone is storable\n  static storable (request, options) {\n    // no cachePath means no caching\n    if (!options.cachePath)\n      return false\n\n    // user explicitly asked not to cache\n    if (options.cache === 'no-store')\n      return false\n\n    // we only cache GET and HEAD requests\n    if (!['GET', 'HEAD'].includes(request.method))\n      return false\n\n    // otherwise, let http-cache-semantics make the decision\n    // based on the request's headers\n    const policy = new CacheSemantics(requestObject(request), emptyResponse, policyOptions)\n    return policy.storable()\n  }\n\n  // returns true if the policy satisfies the request\n  satisfies (request) {\n    const _req = requestObject(request)\n    if (this.request.headers.host !== _req.headers.host)\n      return false\n\n    const negotiatorA = new Negotiator(this.request)\n    const negotiatorB = new Negotiator(_req)\n\n    if (JSON.stringify(negotiatorA.mediaTypes()) !== JSON.stringify(negotiatorB.mediaTypes()))\n      return false\n\n    if (JSON.stringify(negotiatorA.languages()) !== JSON.stringify(negotiatorB.languages()))\n      return false\n\n    if (JSON.stringify(negotiatorA.encodings()) !== JSON.stringify(negotiatorB.encodings()))\n      return false\n\n    if (this.options.integrity)\n      return ssri.parse(this.options.integrity).match(this.entry.integrity)\n\n    return true\n  }\n\n  // returns true if the request and response allow caching\n  storable () {\n    return this.policy.storable()\n  }\n\n  // NOTE: this is a hack to avoid parsing the cache-control\n  // header ourselves, it returns true if the response's\n  // cache-control contains must-revalidate\n  get mustRevalidate () {\n    return !!this.policy._rescc['must-revalidate']\n  }\n\n  // returns true if the cached response requires revalidation\n  // for the given request\n  needsRevalidation (request) {\n    const _req = requestObject(request)\n    // force method to GET because we only cache GETs\n    // but can serve a HEAD from a cached GET\n    _req.method = 'GET'\n    return !this.policy.satisfiesWithoutRevalidation(_req)\n  }\n\n  responseHeaders () {\n    return this.policy.responseHeaders()\n  }\n\n  // returns a new object containing the appropriate headers\n  // to send a revalidation request\n  revalidationHeaders (request) {\n    const _req = requestObject(request)\n    return this.policy.revalidationHeaders(_req)\n  }\n\n  // returns true if the request/response was revalidated\n  // successfully. returns false if a new response was received\n  revalidated (request, response) {\n    const _req = requestObject(request)\n    const _res = responseObject(response)\n    const policy = this.policy.revalidatedPolicy(_req, _res)\n    return !policy.modified\n  }\n}\n\nmodule.exports = CachePolicy\n","const { NotCachedError } = require('./errors.js')\nconst CacheEntry = require('./entry.js')\nconst remote = require('../remote.js')\n\n// do whatever is necessary to get a Response and return it\nconst cacheFetch = async (request, options) => {\n  // try to find a cached entry that satisfies this request\n  const entry = await CacheEntry.find(request, options)\n  if (!entry) {\n    // no cached result, if the cache mode is 'only-if-cached' that's a failure\n    if (options.cache === 'only-if-cached')\n      throw new NotCachedError(request.url)\n\n    // otherwise, we make a request, store it and return it\n    const response = await remote(request, options)\n    const entry = new CacheEntry({ request, response, options })\n    return entry.store('miss')\n  }\n\n  // we have a cached response that satisfies this request, however if the cache\n  // mode is 'no-cache' then we send the revalidation request no matter what\n  if (options.cache === 'no-cache')\n    return entry.revalidate(request, options)\n\n  // if the cached entry is not stale, or if the cache mode is 'force-cache' or\n  // 'only-if-cached' we can respond with the cached entry. set the status\n  // based on the result of needsRevalidation and respond\n  const _needsRevalidation = entry.policy.needsRevalidation(request)\n  if (options.cache === 'force-cache' ||\n      options.cache === 'only-if-cached' ||\n      !_needsRevalidation)\n    return entry.respond(request.method, options, _needsRevalidation ? 'stale' : 'hit')\n\n  // if we got here, the cache entry is stale so revalidate it\n  return entry.revalidate(request, options)\n}\n\ncacheFetch.invalidate = async (request, options) => {\n  if (!options.cachePath)\n    return\n\n  return CacheEntry.invalidate(request, options)\n}\n\nmodule.exports = cacheFetch\n","class NotCachedError extends Error {\n  constructor (url) {\n    super(`request to ${url} failed: cache mode is 'only-if-cached' but no cached response is available.`)\n    this.code = 'ENOTCACHED'\n  }\n}\n\nmodule.exports = {\n  NotCachedError,\n}\n","const { Request, Response } = require('minipass-fetch')\nconst Minipass = require('minipass')\nconst MinipassCollect = require('minipass-collect')\nconst MinipassFlush = require('minipass-flush')\nconst MinipassPipeline = require('minipass-pipeline')\nconst cacache = require('cacache')\nconst url = require('url')\n\nconst CachePolicy = require('./policy.js')\nconst cacheKey = require('./key.js')\nconst remote = require('../remote.js')\n\nconst hasOwnProperty = (obj, prop) => Object.prototype.hasOwnProperty.call(obj, prop)\n\n// maximum amount of data we will buffer into memory\n// if we'll exceed this, we switch to streaming\nconst MAX_MEM_SIZE = 5 * 1024 * 1024 // 5MB\n\n// allow list for request headers that will be written to the cache index\n// note: we will also store any request headers\n// that are named in a response's vary header\nconst KEEP_REQUEST_HEADERS = [\n  'accept-charset',\n  'accept-encoding',\n  'accept-language',\n  'accept',\n  'cache-control',\n]\n\n// allow list for response headers that will be written to the cache index\n// note: we must not store the real response's age header, or when we load\n// a cache policy based on the metadata it will think the cached response\n// is always stale\nconst KEEP_RESPONSE_HEADERS = [\n  'cache-control',\n  'content-encoding',\n  'content-language',\n  'content-type',\n  'date',\n  'etag',\n  'expires',\n  'last-modified',\n  'location',\n  'pragma',\n  'vary',\n]\n\n// return an object containing all metadata to be written to the index\nconst getMetadata = (request, response, options) => {\n  const metadata = {\n    time: Date.now(),\n    url: request.url,\n    reqHeaders: {},\n    resHeaders: {},\n  }\n\n  // only save the status if it's not a 200 or 304\n  if (response.status !== 200 && response.status !== 304)\n    metadata.status = response.status\n\n  for (const name of KEEP_REQUEST_HEADERS) {\n    if (request.headers.has(name))\n      metadata.reqHeaders[name] = request.headers.get(name)\n  }\n\n  // if the request's host header differs from the host in the url\n  // we need to keep it, otherwise it's just noise and we ignore it\n  const host = request.headers.get('host')\n  const parsedUrl = new url.URL(request.url)\n  if (host && parsedUrl.host !== host)\n    metadata.reqHeaders.host = host\n\n  // if the response has a vary header, make sure\n  // we store the relevant request headers too\n  if (response.headers.has('vary')) {\n    const vary = response.headers.get('vary')\n    // a vary of \"*\" means every header causes a different response.\n    // in that scenario, we do not include any additional headers\n    // as the freshness check will always fail anyway and we don't\n    // want to bloat the cache indexes\n    if (vary !== '*') {\n      // copy any other request headers that will vary the response\n      const varyHeaders = vary.trim().toLowerCase().split(/\\s*,\\s*/)\n      for (const name of varyHeaders) {\n        // explicitly ignore accept-encoding here\n        if (name !== 'accept-encoding' && request.headers.has(name))\n          metadata.reqHeaders[name] = request.headers.get(name)\n      }\n    }\n  }\n\n  for (const name of KEEP_RESPONSE_HEADERS) {\n    if (response.headers.has(name))\n      metadata.resHeaders[name] = response.headers.get(name)\n  }\n\n  // we only store accept-encoding and content-encoding if the user\n  // has disabled automatic compression and decompression in minipass-fetch\n  // since if it's enabled (the default) then the content will have\n  // already been decompressed making the header a lie\n  if (options.compress === false) {\n    metadata.reqHeaders['accept-encoding'] = request.headers.get('accept-encoding')\n    metadata.resHeaders['content-encoding'] = response.headers.get('content-encoding')\n  }\n\n  return metadata\n}\n\n// symbols used to hide objects that may be lazily evaluated in a getter\nconst _request = Symbol('request')\nconst _response = Symbol('response')\nconst _policy = Symbol('policy')\n\nclass CacheEntry {\n  constructor ({ entry, request, response, options }) {\n    if (entry) {\n      this.key = entry.key\n      this.entry = entry\n      // previous versions of this module didn't write an explicit timestamp in\n      // the metadata, so fall back to the entry's timestamp. we can't use the\n      // entry timestamp to determine staleness because cacache will update it\n      // when it verifies its data\n      this.entry.metadata.time = this.entry.metadata.time || this.entry.time\n    } else\n      this.key = cacheKey(request)\n\n    this.options = options\n\n    // these properties are behind getters that lazily evaluate\n    this[_request] = request\n    this[_response] = response\n    this[_policy] = null\n  }\n\n  // returns a CacheEntry instance that satisfies the given request\n  // or undefined if no existing entry satisfies\n  static async find (request, options) {\n    try {\n      // compacts the index and returns an array of unique entries\n      var matches = await cacache.index.compact(options.cachePath, cacheKey(request), (A, B) => {\n        const entryA = new CacheEntry({ entry: A, options })\n        const entryB = new CacheEntry({ entry: B, options })\n        return entryA.policy.satisfies(entryB.request)\n      }, {\n        validateEntry: (entry) => {\n          // if an integrity is null, it needs to have a status specified\n          if (entry.integrity === null)\n            return !!(entry.metadata && entry.metadata.status)\n\n          return true\n        },\n      })\n    } catch (err) {\n      // if the compact request fails, ignore the error and return\n      return\n    }\n\n    // a cache mode of 'reload' means to behave as though we have no cache\n    // on the way to the network. return undefined to allow cacheFetch to\n    // create a brand new request no matter what.\n    if (options.cache === 'reload')\n      return\n\n    // find the specific entry that satisfies the request\n    let match\n    for (const entry of matches) {\n      const _entry = new CacheEntry({\n        entry,\n        options,\n      })\n\n      if (_entry.policy.satisfies(request)) {\n        match = _entry\n        break\n      }\n    }\n\n    return match\n  }\n\n  // if the user made a PUT/POST/PATCH then we invalidate our\n  // cache for the same url by deleting the index entirely\n  static async invalidate (request, options) {\n    const key = cacheKey(request)\n    try {\n      await cacache.rm.entry(options.cachePath, key, { removeFully: true })\n    } catch (err) {\n      // ignore errors\n    }\n  }\n\n  get request () {\n    if (!this[_request]) {\n      this[_request] = new Request(this.entry.metadata.url, {\n        method: 'GET',\n        headers: this.entry.metadata.reqHeaders,\n      })\n    }\n\n    return this[_request]\n  }\n\n  get response () {\n    if (!this[_response]) {\n      this[_response] = new Response(null, {\n        url: this.entry.metadata.url,\n        counter: this.options.counter,\n        status: this.entry.metadata.status || 200,\n        headers: {\n          ...this.entry.metadata.resHeaders,\n          'content-length': this.entry.size,\n        },\n      })\n    }\n\n    return this[_response]\n  }\n\n  get policy () {\n    if (!this[_policy]) {\n      this[_policy] = new CachePolicy({\n        entry: this.entry,\n        request: this.request,\n        response: this.response,\n        options: this.options,\n      })\n    }\n\n    return this[_policy]\n  }\n\n  // wraps the response in a pipeline that stores the data\n  // in the cache while the user consumes it\n  async store (status) {\n    // if we got a status other than 200, 301, or 308,\n    // or the CachePolicy forbid storage, append the\n    // cache status header and return it untouched\n    if (this.request.method !== 'GET' || ![200, 301, 308].includes(this.response.status) || !this.policy.storable()) {\n      this.response.headers.set('x-local-cache-status', 'skip')\n      return this.response\n    }\n\n    const size = this.response.headers.get('content-length')\n    const fitsInMemory = !!size && Number(size) < MAX_MEM_SIZE\n    const shouldBuffer = this.options.memoize !== false && fitsInMemory\n    const cacheOpts = {\n      algorithms: this.options.algorithms,\n      metadata: getMetadata(this.request, this.response, this.options),\n      size,\n      memoize: fitsInMemory && this.options.memoize,\n    }\n\n    let body = null\n    // we only set a body if the status is a 200, redirects are\n    // stored as metadata only\n    if (this.response.status === 200) {\n      let cacheWriteResolve, cacheWriteReject\n      const cacheWritePromise = new Promise((resolve, reject) => {\n        cacheWriteResolve = resolve\n        cacheWriteReject = reject\n      })\n\n      body = new MinipassPipeline(new MinipassFlush({\n        flush () {\n          return cacheWritePromise\n        },\n      }))\n\n      let abortStream, onResume\n      if (shouldBuffer) {\n        // if the result fits in memory, use a collect stream to gather\n        // the response and write it to cacache while also passing it through\n        // to the user\n        onResume = () => {\n          const collector = new MinipassCollect.PassThrough()\n          abortStream = collector\n          collector.on('collect', (data) => {\n            // TODO if the cache write fails, log a warning but return the response anyway\n            cacache.put(this.options.cachePath, this.key, data, cacheOpts).then(cacheWriteResolve, cacheWriteReject)\n          })\n          body.unshift(collector)\n          body.unshift(this.response.body)\n        }\n      } else {\n        // if it does not fit in memory, create a tee stream and use\n        // that to pipe to both the cache and the user simultaneously\n        onResume = () => {\n          const tee = new Minipass()\n          const cacheStream = cacache.put.stream(this.options.cachePath, this.key, cacheOpts)\n          abortStream = cacheStream\n          tee.pipe(cacheStream)\n          // TODO if the cache write fails, log a warning but return the response anyway\n          cacheStream.promise().then(cacheWriteResolve, cacheWriteReject)\n          body.unshift(tee)\n          body.unshift(this.response.body)\n        }\n      }\n\n      body.once('resume', onResume)\n      body.once('end', () => body.removeListener('resume', onResume))\n      this.response.body.on('error', (err) => {\n        // the abortStream will either be a MinipassCollect if we buffer\n        // or a cacache write stream, either way be sure to listen for\n        // errors from the actual response and avoid writing data that we\n        // know to be invalid to the cache\n        abortStream.destroy(err)\n      })\n    } else\n      await cacache.index.insert(this.options.cachePath, this.key, null, cacheOpts)\n\n    // note: we do not set the x-local-cache-hash header because we do not know\n    // the hash value until after the write to the cache completes, which doesn't\n    // happen until after the response has been sent and it's too late to write\n    // the header anyway\n    this.response.headers.set('x-local-cache', encodeURIComponent(this.options.cachePath))\n    this.response.headers.set('x-local-cache-key', encodeURIComponent(this.key))\n    this.response.headers.set('x-local-cache-mode', shouldBuffer ? 'buffer' : 'stream')\n    this.response.headers.set('x-local-cache-status', status)\n    this.response.headers.set('x-local-cache-time', new Date().toISOString())\n    const newResponse = new Response(body, {\n      url: this.response.url,\n      status: this.response.status,\n      headers: this.response.headers,\n      counter: this.options.counter,\n    })\n    return newResponse\n  }\n\n  // use the cached data to create a response and return it\n  async respond (method, options, status) {\n    let response\n    const size = Number(this.response.headers.get('content-length'))\n    const fitsInMemory = !!size && size < MAX_MEM_SIZE\n    const shouldBuffer = this.options.memoize !== false && fitsInMemory\n    if (method === 'HEAD' || [301, 308].includes(this.response.status)) {\n      // if the request is a HEAD, or the response is a redirect,\n      // then the metadata in the entry already includes everything\n      // we need to build a response\n      response = this.response\n    } else {\n      // we're responding with a full cached response, so create a body\n      // that reads from cacache and attach it to a new Response\n      const body = new Minipass()\n      const removeOnResume = () => body.removeListener('resume', onResume)\n      let onResume\n      if (shouldBuffer) {\n        onResume = async () => {\n          removeOnResume()\n          try {\n            const content = await cacache.get.byDigest(this.options.cachePath, this.entry.integrity, { memoize: this.options.memoize })\n            body.end(content)\n          } catch (err) {\n            if (err.code === 'EINTEGRITY')\n              await cacache.rm.content(this.options.cachePath, this.entry.integrity, { memoize: this.options.memoize })\n            if (err.code === 'ENOENT' || err.code === 'EINTEGRITY')\n              await CacheEntry.invalidate(this.request, this.options)\n            body.emit('error', err)\n          }\n        }\n      } else {\n        onResume = () => {\n          const cacheStream = cacache.get.stream.byDigest(this.options.cachePath, this.entry.integrity, { memoize: this.options.memoize })\n          cacheStream.on('error', async (err) => {\n            cacheStream.pause()\n            if (err.code === 'EINTEGRITY')\n              await cacache.rm.content(this.options.cachePath, this.entry.integrity, { memoize: this.options.memoize })\n            if (err.code === 'ENOENT' || err.code === 'EINTEGRITY')\n              await CacheEntry.invalidate(this.request, this.options)\n            body.emit('error', err)\n            cacheStream.resume()\n          })\n          cacheStream.pipe(body)\n        }\n      }\n\n      body.once('resume', onResume)\n      body.once('end', removeOnResume)\n      response = new Response(body, {\n        url: this.entry.metadata.url,\n        counter: options.counter,\n        status: 200,\n        headers: {\n          ...this.policy.responseHeaders(),\n        },\n      })\n    }\n\n    response.headers.set('x-local-cache', encodeURIComponent(this.options.cachePath))\n    response.headers.set('x-local-cache-hash', encodeURIComponent(this.entry.integrity))\n    response.headers.set('x-local-cache-key', encodeURIComponent(this.key))\n    response.headers.set('x-local-cache-mode', shouldBuffer ? 'buffer' : 'stream')\n    response.headers.set('x-local-cache-status', status)\n    response.headers.set('x-local-cache-time', new Date(this.entry.metadata.time).toUTCString())\n    return response\n  }\n\n  // use the provided request along with this cache entry to\n  // revalidate the stored response. returns a response, either\n  // from the cache or from the update\n  async revalidate (request, options) {\n    const revalidateRequest = new Request(request, {\n      headers: this.policy.revalidationHeaders(request),\n    })\n\n    try {\n      // NOTE: be sure to remove the headers property from the\n      // user supplied options, since we have already defined\n      // them on the new request object. if they're still in the\n      // options then those will overwrite the ones from the policy\n      var response = await remote(revalidateRequest, {\n        ...options,\n        headers: undefined,\n      })\n    } catch (err) {\n      // if the network fetch fails, return the stale\n      // cached response unless it has a cache-control\n      // of 'must-revalidate'\n      if (!this.policy.mustRevalidate)\n        return this.respond(request.method, options, 'stale')\n\n      throw err\n    }\n\n    if (this.policy.revalidated(revalidateRequest, response)) {\n      // we got a 304, write a new index to the cache and respond from cache\n      const metadata = getMetadata(request, response, options)\n      // 304 responses do not include headers that are specific to the response data\n      // since they do not include a body, so we copy values for headers that were\n      // in the old cache entry to the new one, if the new metadata does not already\n      // include that header\n      for (const name of KEEP_RESPONSE_HEADERS) {\n        if (!hasOwnProperty(metadata.resHeaders, name) && hasOwnProperty(this.entry.metadata.resHeaders, name))\n          metadata.resHeaders[name] = this.entry.metadata.resHeaders[name]\n      }\n\n      try {\n        await cacache.index.insert(options.cachePath, this.key, this.entry.integrity, {\n          size: this.entry.size,\n          metadata,\n        })\n      } catch (err) {\n        // if updating the cache index fails, we ignore it and\n        // respond anyway\n      }\n      return this.respond(request.method, options, 'revalidated')\n    }\n\n    // if we got a modified response, create a new entry based on it\n    const newEntry = new CacheEntry({\n      request,\n      response,\n      options,\n    })\n\n    // respond with the new entry while writing it to the cache\n    return newEntry.store('updated')\n  }\n}\n\nmodule.exports = CacheEntry\n","const { URL, format } = require('url')\n\n// options passed to url.format() when generating a key\nconst formatOptions = {\n  auth: false,\n  fragment: false,\n  search: true,\n  unicode: false,\n}\n\n// returns a string to be used as the cache key for the Request\nconst cacheKey = (request) => {\n  const parsed = new URL(request.url)\n  return `make-fetch-happen:request-cache:${format(parsed, formatOptions)}`\n}\n\nmodule.exports = cacheKey\n","const Minipass = require('minipass')\nconst MinipassPipeline = require('minipass-pipeline')\nconst fetch = require('minipass-fetch')\nconst promiseRetry = require('promise-retry')\nconst ssri = require('ssri')\n\nconst getAgent = require('./agent.js')\nconst pkg = require('../package.json')\n\nconst USER_AGENT = `${pkg.name}/${pkg.version} (+https://npm.im/${pkg.name})`\n\nconst RETRY_ERRORS = [\n  'ECONNRESET', // remote socket closed on us\n  'ECONNREFUSED', // remote host refused to open connection\n  'EADDRINUSE', // failed to bind to a local port (proxy?)\n  'ETIMEDOUT', // someone in the transaction is WAY TOO SLOW\n  'ERR_SOCKET_TIMEOUT', // same as above, but this one comes from agentkeepalive\n  // Known codes we do NOT retry on:\n  // ENOTFOUND (getaddrinfo failure. Either bad hostname, or offline)\n]\n\nconst RETRY_TYPES = [\n  'request-timeout',\n]\n\n// make a request directly to the remote source,\n// retrying certain classes of errors as well as\n// following redirects (through the cache if necessary)\n// and verifying response integrity\nconst remoteFetch = (request, options) => {\n  const agent = getAgent(request.url, options)\n  if (!request.headers.has('connection'))\n    request.headers.set('connection', agent ? 'keep-alive' : 'close')\n\n  if (!request.headers.has('user-agent'))\n    request.headers.set('user-agent', USER_AGENT)\n\n  // keep our own options since we're overriding the agent\n  // and the redirect mode\n  const _opts = {\n    ...options,\n    agent,\n    redirect: 'manual',\n  }\n\n  return promiseRetry(async (retryHandler, attemptNum) => {\n    const req = new fetch.Request(request, _opts)\n    try {\n      let res = await fetch(req, _opts)\n      if (_opts.integrity && res.status === 200) {\n        // we got a 200 response and the user has specified an expected\n        // integrity value, so wrap the response in an ssri stream to verify it\n        const integrityStream = ssri.integrityStream({ integrity: _opts.integrity })\n        res = new fetch.Response(new MinipassPipeline(res.body, integrityStream), res)\n      }\n\n      res.headers.set('x-fetch-attempts', attemptNum)\n\n      // do not retry POST requests, or requests with a streaming body\n      // do retry requests with a 408, 420, 429 or 500+ status in the response\n      const isStream = Minipass.isStream(req.body)\n      const isRetriable = req.method !== 'POST' &&\n          !isStream &&\n          ([408, 420, 429].includes(res.status) || res.status >= 500)\n\n      if (isRetriable) {\n        if (typeof options.onRetry === 'function')\n          options.onRetry(res)\n\n        return retryHandler(res)\n      }\n\n      return res\n    } catch (err) {\n      const code = (err.code === 'EPROMISERETRY')\n        ? err.retried.code\n        : err.code\n\n      // err.retried will be the thing that was thrown from above\n      // if it's a response, we just got a bad status code and we\n      // can re-throw to allow the retry\n      const isRetryError = err.retried instanceof fetch.Response ||\n        (RETRY_ERRORS.includes(code) && RETRY_TYPES.includes(err.type))\n\n      if (req.method === 'POST' || isRetryError)\n        throw err\n\n      if (typeof options.onRetry === 'function')\n        options.onRetry(err)\n\n      return retryHandler(err)\n    }\n  }, options.retry).catch((err) => {\n    // don't reject for http errors, just return them\n    if (err.status >= 400 && err.type !== 'system')\n      return err\n\n    throw err\n  })\n}\n\nmodule.exports = remoteFetch\n","\nconst LRU = require('lru-cache')\nconst url = require('url')\nconst isLambda = require('is-lambda')\n\nconst AGENT_CACHE = new LRU({ max: 50 })\nconst HttpAgent = require('agentkeepalive')\nconst HttpsAgent = HttpAgent.HttpsAgent\n\nmodule.exports = getAgent\n\nconst getAgentTimeout = timeout =>\n  typeof timeout !== 'number' || !timeout ? 0 : timeout + 1\n\nconst getMaxSockets = maxSockets => maxSockets || 15\n\nfunction getAgent (uri, opts) {\n  const parsedUri = new url.URL(typeof uri === 'string' ? uri : uri.url)\n  const isHttps = parsedUri.protocol === 'https:'\n  const pxuri = getProxyUri(parsedUri.href, opts)\n\n  // If opts.timeout is zero, set the agentTimeout to zero as well. A timeout\n  // of zero disables the timeout behavior (OS limits still apply). Else, if\n  // opts.timeout is a non-zero value, set it to timeout + 1, to ensure that\n  // the node-fetch-npm timeout will always fire first, giving us more\n  // consistent errors.\n  const agentTimeout = getAgentTimeout(opts.timeout)\n  const agentMaxSockets = getMaxSockets(opts.maxSockets)\n\n  const key = [\n    `https:${isHttps}`,\n    pxuri\n      ? `proxy:${pxuri.protocol}//${pxuri.host}:${pxuri.port}`\n      : '>no-proxy<',\n    `local-address:${opts.localAddress || '>no-local-address<'}`,\n    `strict-ssl:${isHttps ? opts.rejectUnauthorized : '>no-strict-ssl<'}`,\n    `ca:${(isHttps && opts.ca) || '>no-ca<'}`,\n    `cert:${(isHttps && opts.cert) || '>no-cert<'}`,\n    `key:${(isHttps && opts.key) || '>no-key<'}`,\n    `timeout:${agentTimeout}`,\n    `maxSockets:${agentMaxSockets}`,\n  ].join(':')\n\n  if (opts.agent != null) { // `agent: false` has special behavior!\n    return opts.agent\n  }\n\n  // keep alive in AWS lambda makes no sense\n  const lambdaAgent = !isLambda ? null\n    : isHttps ? require('https').globalAgent\n    : require('http').globalAgent\n\n  if (isLambda && !pxuri)\n    return lambdaAgent\n\n  if (AGENT_CACHE.peek(key))\n    return AGENT_CACHE.get(key)\n\n  if (pxuri) {\n    const pxopts = isLambda ? {\n      ...opts,\n      agent: lambdaAgent,\n    } : opts\n    const proxy = getProxy(pxuri, pxopts, isHttps)\n    AGENT_CACHE.set(key, proxy)\n    return proxy\n  }\n\n  const agent = isHttps ? new HttpsAgent({\n    maxSockets: agentMaxSockets,\n    ca: opts.ca,\n    cert: opts.cert,\n    key: opts.key,\n    localAddress: opts.localAddress,\n    rejectUnauthorized: opts.rejectUnauthorized,\n    timeout: agentTimeout,\n  }) : new HttpAgent({\n    maxSockets: agentMaxSockets,\n    localAddress: opts.localAddress,\n    timeout: agentTimeout,\n  })\n  AGENT_CACHE.set(key, agent)\n  return agent\n}\n\nfunction checkNoProxy (uri, opts) {\n  const host = new url.URL(uri).hostname.split('.').reverse()\n  let noproxy = (opts.noProxy || getProcessEnv('no_proxy'))\n  if (typeof noproxy === 'string')\n    noproxy = noproxy.split(/\\s*,\\s*/g)\n\n  return noproxy && noproxy.some(no => {\n    const noParts = no.split('.').filter(x => x).reverse()\n    if (!noParts.length)\n      return false\n    for (let i = 0; i < noParts.length; i++) {\n      if (host[i] !== noParts[i])\n        return false\n    }\n    return true\n  })\n}\n\nmodule.exports.getProcessEnv = getProcessEnv\n\nfunction getProcessEnv (env) {\n  if (!env)\n    return\n\n  let value\n\n  if (Array.isArray(env)) {\n    for (const e of env) {\n      value = process.env[e] ||\n        process.env[e.toUpperCase()] ||\n        process.env[e.toLowerCase()]\n      if (typeof value !== 'undefined')\n        break\n    }\n  }\n\n  if (typeof env === 'string') {\n    value = process.env[env] ||\n      process.env[env.toUpperCase()] ||\n      process.env[env.toLowerCase()]\n  }\n\n  return value\n}\n\nmodule.exports.getProxyUri = getProxyUri\nfunction getProxyUri (uri, opts) {\n  const protocol = new url.URL(uri).protocol\n\n  const proxy = opts.proxy ||\n    (\n      protocol === 'https:' &&\n      getProcessEnv('https_proxy')\n    ) ||\n    (\n      protocol === 'http:' &&\n      getProcessEnv(['https_proxy', 'http_proxy', 'proxy'])\n    )\n  if (!proxy)\n    return null\n\n  const parsedProxy = (typeof proxy === 'string') ? new url.URL(proxy) : proxy\n\n  return !checkNoProxy(uri, opts) && parsedProxy\n}\n\nconst getAuth = u =>\n  u.username && u.password ? decodeURIComponent(`${u.username}:${u.password}`)\n  : u.username ? decodeURIComponent(u.username)\n  : null\n\nconst getPath = u => u.pathname + u.search + u.hash\n\nconst HttpProxyAgent = require('http-proxy-agent')\nconst HttpsProxyAgent = require('https-proxy-agent')\nconst SocksProxyAgent = require('socks-proxy-agent')\nmodule.exports.getProxy = getProxy\nfunction getProxy (proxyUrl, opts, isHttps) {\n  const popts = {\n    host: proxyUrl.hostname,\n    port: proxyUrl.port,\n    protocol: proxyUrl.protocol,\n    path: getPath(proxyUrl),\n    auth: getAuth(proxyUrl),\n    ca: opts.ca,\n    cert: opts.cert,\n    key: opts.key,\n    timeout: getAgentTimeout(opts.timeout),\n    localAddress: opts.localAddress,\n    maxSockets: getMaxSockets(opts.maxSockets),\n    rejectUnauthorized: opts.rejectUnauthorized,\n  }\n\n  if (proxyUrl.protocol === 'http:' || proxyUrl.protocol === 'https:') {\n    if (!isHttps)\n      return new HttpProxyAgent(popts)\n    else\n      return new HttpsProxyAgent(popts)\n  } else if (proxyUrl.protocol.startsWith('socks'))\n    return new SocksProxyAgent(popts)\n  else {\n    throw Object.assign(\n      new Error(`unsupported proxy protocol: '${proxyUrl.protocol}'`),\n      {\n        url: proxyUrl.href,\n      }\n    )\n  }\n}\n","module.exports = {\n  \"_from\": \"make-fetch-happen@^9.1.0\",\n  \"_id\": \"make-fetch-happen@9.1.0\",\n  \"_inBundle\": false,\n  \"_integrity\": \"sha1-UwhaCeeXFDPmdl95cb9j9OBcuWg=\",\n  \"_location\": \"/make-fetch-happen\",\n  \"_phantomChildren\": {},\n  \"_requested\": {\n    \"type\": \"range\",\n    \"registry\": true,\n    \"raw\": \"make-fetch-happen@^9.1.0\",\n    \"name\": \"make-fetch-happen\",\n    \"escapedName\": \"make-fetch-happen\",\n    \"rawSpec\": \"^9.1.0\",\n    \"saveSpec\": null,\n    \"fetchSpec\": \"^9.1.0\"\n  },\n  \"_requiredBy\": [\n    \"/node-gyp\"\n  ],\n  \"_resolved\": \"https://registry.npmmirror.com/make-fetch-happen/download/make-fetch-happen-9.1.0.tgz\",\n  \"_shasum\": \"53085a09e7971433e6765f7971bf63f4e05cb968\",\n  \"_spec\": \"make-fetch-happen@^9.1.0\",\n  \"_where\": \"D:\\\\毕设小程序\\\\闲者集市\\\\proj\\\\node_modules\\\\node-gyp\",\n  \"author\": {\n    \"name\": \"Kat Marchán\",\n    \"email\": \"kzm@zkat.tech\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/npm/make-fetch-happen/issues\"\n  },\n  \"bundleDependencies\": false,\n  \"dependencies\": {\n    \"agentkeepalive\": \"^4.1.3\",\n    \"cacache\": \"^15.2.0\",\n    \"http-cache-semantics\": \"^4.1.0\",\n    \"http-proxy-agent\": \"^4.0.1\",\n    \"https-proxy-agent\": \"^5.0.0\",\n    \"is-lambda\": \"^1.0.1\",\n    \"lru-cache\": \"^6.0.0\",\n    \"minipass\": \"^3.1.3\",\n    \"minipass-collect\": \"^1.0.2\",\n    \"minipass-fetch\": \"^1.3.2\",\n    \"minipass-flush\": \"^1.0.5\",\n    \"minipass-pipeline\": \"^1.2.4\",\n    \"negotiator\": \"^0.6.2\",\n    \"promise-retry\": \"^2.0.1\",\n    \"socks-proxy-agent\": \"^6.0.0\",\n    \"ssri\": \"^8.0.0\"\n  },\n  \"deprecated\": false,\n  \"description\": \"Opinionated, caching, retrying fetch client\",\n  \"devDependencies\": {\n    \"eslint\": \"^7.26.0\",\n    \"eslint-plugin-import\": \"^2.23.2\",\n    \"eslint-plugin-node\": \"^11.1.0\",\n    \"eslint-plugin-promise\": \"^5.1.0\",\n    \"eslint-plugin-standard\": \"^5.0.0\",\n    \"mkdirp\": \"^1.0.4\",\n    \"nock\": \"^13.0.11\",\n    \"npmlog\": \"^5.0.0\",\n    \"require-inject\": \"^1.4.2\",\n    \"rimraf\": \"^3.0.2\",\n    \"safe-buffer\": \"^5.2.1\",\n    \"standard-version\": \"^9.3.0\",\n    \"tap\": \"^15.0.9\"\n  },\n  \"engines\": {\n    \"node\": \">= 10\"\n  },\n  \"files\": [\n    \"lib\"\n  ],\n  \"homepage\": \"https://github.com/npm/make-fetch-happen#readme\",\n  \"keywords\": [\n    \"http\",\n    \"request\",\n    \"fetch\",\n    \"mean girls\",\n    \"caching\",\n    \"cache\",\n    \"subresource integrity\"\n  ],\n  \"license\": \"ISC\",\n  \"main\": \"lib/index.js\",\n  \"name\": \"make-fetch-happen\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/npm/make-fetch-happen.git\"\n  },\n  \"scripts\": {\n    \"eslint\": \"eslint\",\n    \"lint\": \"npm run eslint -- lib test\",\n    \"lintfix\": \"npm run lint -- --fix\",\n    \"posttest\": \"npm run lint\",\n    \"postversion\": \"npm publish\",\n    \"prepublishOnly\": \"git push --follow-tags\",\n    \"preversion\": \"npm t\",\n    \"test\": \"tap\"\n  },\n  \"tap\": {\n    \"color\": 1,\n    \"files\": \"test/*.js\",\n    \"check-coverage\": true\n  },\n  \"version\": \"9.1.0\"\n}\n"]}